\section{Description of the algorithms}

\subsection*{Data structure for a vertex}
The data structure for a vertex was implemented as follows:
\begin{enumerate}
    \item \verb|Name| of the vertex;
    \item \verb|Key| is a kind of weight of a vertex;
    \item \verb|Parent| indicates the parent of a vertex;
    \item \verb|VerticesAdjacent| is a set which contains all adjacent nodes; 
    \item \verb|Visited| that indicates if a node has already been visited or not.
\end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|IsVisited|: returns the value of \verb|Visited|;
    \item \verb|SetVisited|: sets the value of \verb|Visited| to true or false as indicated by the parameter;
    \item \verb|AddAdjacentVertices|: adds an adjacent vertex to the \verb|VerticesAdjacent| of a node;
    \item \verb|RemoveAdjecentVertices|: removes an adjacent vertex to the \verb|VerticesAdjacent|;
    \item \verb|Equals|: checks if two vetrices have the same name.
\end{enumerate}
These operations have been implemented in order to have a constant computational complexity O(1).

\subsection*{Data structure for an edge}
The data structure for am edge was implemented as follows:
\begin{enumerate}
    \item \verb|U| represents one end of the edge;
    \item \verb|V| represents one end of the edge;
    \item \verb|Weight| indicates the weight of the edge.
    \end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|CompareTo|: compares the weight of two different edges and returns an indication of their relative value;
    \item \verb|Equals|: checks if two edges have the same ends and weight.
\end{enumerate}
These operations have been implemented in order to have a constant computational complexity O(1).

\subsection*{Data structure for a graph}
The data structure for a graph was implemented as follows:
\begin{enumerate}
    \item \verb|V| is a set of vertices;
    \item \verb|E| is a collection of edges.
    \end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|AddVertex|: adds a vertex to the graph;
    \item \verb|AddEdge|: adds an edge to the graph;
    \item \verb|RemoveEdge|: removes an edge from the collection \verb|E|;
    \item \verb|GetWeight|: returns the weight of an edge given two vertices;
    \item \verb|LoadFromFileAsync|: creates the graph starting from the selected file.
\end{enumerate}
These operations have been implemented in order to have a constant computational complexity O(1).

\subsection{Prim}
\subsubsection{Introduction}
The base version of Prim's Algorithm has a computational complexity of $\mathcal{O}(mn)$.
The base idea is to start with a random vertex and choose, for each interaction, the edge 
that connects with the lowest possible weight the \textit{MST} node tree at the new vertex.\\
The algorithm can be optimized by using the correct data structure.
In fact, by using the Heap we can compute the minimum weight in logarithmic time and the complexity become $\mathcal{O}(mlog(n))$.

\begin{verbatim}
  Prim(G,s)
    for each u in V do
      [u] <- +inf
      parent[u] <- nil
    key[s] <- 0
    Q <- V
    while Q not empty do
      u <- extractMin(Q)
      for each v adjacent to u do
        if v in Q and w(u,v) < key[v] then
          parent[v] <- u
          key[v] <- w(u,v)
\end{verbatim}

\subsubsection{Our implementation}
For the heap structure we used a \textbf{PriorityQueue} that was recently added in .NET 6.0.
The PriorityQueue creates an association between the Vertex object that we pass to it and the weight that vertex has.\\
Our implementation is slightly different from the original one. In fact, instead of filling the PriorityQueue with 
all the vertices, we started by inserting only the starting node with the weight of zero.\\
Then, in the while, we extracting the minimum vertex and we check if the vertex was already visited.
If it was visited we skip it and we extract another one.
Otherwise we mark it as visited, and we starting to check all its adjacent vertices.
In the if condition, we check that the adjacent vertices was not visited yet and if the conditions succeeds 
we adding the vertex to the PriorityQueue.

\subsection{Kruskal naive}
\subsection{Kruskal with Union-Find}
\subsubsection{Introduction}
In order to speed up naive Kruskal's Algorithm, especially the checking of the cyclicity we can use a new 
data structure called: \textbf{Disjoint Set} or \textbf{Union Find}.\\
Thanks to this new approach we are able to reduce the time complexity to $O(mlog(n))$;
\begin{verbatim}
    Kruskal-Union-Find(G)
      A = empty_set
      U = union_find_ds
      for each vertex v in G.V
        U.MakeSet(v)
      sort the edges of G.E into increasing order by weight w
      for each edge (v, w) in G.E, taken in increasing order by weight
        if U.FindSet(v) != U.FindSet(w)
          A = A U {(v, w)}
          U.Union(v, w)
      return A
\end{verbatim}

The check for the cyclicality of the graph is replaced with the check whether the two vertices of edge $(v, w)$ 
belong to two trees or not distinct. If the two vertices have the root node in common it means that there already 
exists a path from $v$ to $w$ and thus adding the edge $(v, w)$ it would create a cycle.
If, on the other hand, the two vertices belong to two different trees, then the introduction of such an arch will 
not create a cycle in the graph.
Then, the edge $(v, w)$ will be added to $A$ and the two trees will be joined based on their \textit{size}.

\subsubsection{Our implementation}
Since in C\# the UF data structure is not present, we implemented it us.\\
The principal methods available in the Union Find data structure are:
\begin{enumerate}
    \item \verb|MakeSet(x)|: where we pass the data that we want to insert in the data structure and we return 
        if the data was inserted or not. The time complexity of this method is $O(1)$;
    \item \verb|FindSet(x)|: returns the root node of the tree to which the node that has value $x$ belongs.
        The time complexity of this method is $O(log n)$;
    \item \verb|Union(x, y)|: given the values of the two nodes, we determine the parent node for each node and 
        if they belong to different tree we merge them in base at their size. The time complexity of this 
        method is $O(log(n))$.
\end{enumerate}

