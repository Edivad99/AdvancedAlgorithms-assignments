\section{Description of the algorithms}

\subsection{Data structures}
In the following subsections, we will illustrate the main data structures used as a common base for all the 
three algorithms for solving the \textbf{Travelling Salesman Problem}.

\subsubsection{Data structure for a vertex}
The data structure for a vertex was implemented as follows:
\begin{enumerate}
    \item \verb|Name| of the vertex;
    \item \verb|Key| is a kind of weight of a vertex;
    \item \verb|Parent| indicates the parent of a vertex;
    \item \verb|VerticesAdjacent| is a set which contains all adjacent nodes; 
    \item \verb|Visited| that indicates if a node has already been visited or not;
    \item \verb|X| is a coordinate of the vertex;
    \item \verb|Y| is a coordinate of the vertex
\end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|IsVisited|: returns the value of \verb|Visited|;
    \item \verb|SetVisited|: sets the value of \verb|Visited| to true or false as indicated by the parameter;
    \item \verb|AddAdjacentVertices|: adds an adjacent vertex to the \verb|VerticesAdjacent| of a node;
    \item \verb|Equals|: checks if two vetrices have the same name;
    \item \verb|ClearStatus|: sets the value of \verb|Visited| to false and \verb|Key| equal to 0;
    \item \verb|ConvertGeoCoordinate|: converts a given coordinate to radians.
\end{enumerate}
These operations have been implemented in order to have a constant computational complexity $\mathcal{O}(1)$.

\subsubsection{Data structure for an edge}
The data structure for an edge is the following one:
\begin{enumerate}
    \item \verb|U| represents one end of the edge;
    \item \verb|V| represents one end of the edge;
    \item \verb|Distance| indicates the distance between the two vertices \verb|U| and \verb|V|.
    \end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|CompareTo|: compares the weight of two different edges and returns an indication of which one is the greater;
    \item \verb|Equals|: checks if two edges have the same ends and weight.
\end{enumerate}
These operations have been implemented in order to have a constant computational complexity $\mathcal{O}(1)$.

\subsubsection{Data structure for a graph}
The data structure for a graph was implemented as follows:
\begin{enumerate}
    \item \verb|V| is a dictionary of vertices, with key the name of the vertex;
    \item \verb|E| is a dictionary of edges, with key the tuple of the names of the two vertices;
    \item \verb|Type| is an enumeration type which indicates the format of the coordinate. In our algorithms, it can assume one of the following two values:
    \begin{itemize}
        \item \verb|EUC_2D| when the coordinates are represented in an euclidean way;
        \item \verb|GEO| when the coordinates are represented as latitude and longitude.
    \end{itemize}
\end{enumerate}
\noindent
The implemented methods were:
\begin{enumerate}
    \item \verb|AddVertex|: adds a vertex to the graph;
    \item \verb|AddEdge|: adds an edge to the graph;
    \item \verb|GetWeight|: returns the weight of an edge given two vertices;
    \item \verb|ClearVerticesStatus|: clear all vertices calling \verb|ClearStatus| for each vertex;
    \item \verb|PrintAdjacentMatrix|: utility function for printing the \textit{adjacency matrix};
    \item \verb|LoadFromFileAsync|: creates the graph starting from the selected file.
\end{enumerate}
These operations (except \verb|LoadFromFileAsync|, \verb|ClearVerticesStatus| and \verb|PrintAdjacentMatrix|) have been implemented in order to have a constant computational complexity $\mathcal{O}(1)$.

\subsection{Nearest Neighbor}

\subsubsection{Introduction}
The \textit{Nearest Neighbor} algorithm for solving TSP falls into the class of constructive heuristics. These are a family of algorithms which, starting from an initial vertex, build the solution one vertex at a time. We add this vertex to a subset corresponding to the partial solution and this addition is performed according to some rules, until an approximate solution is found.

\subsubsection{Algorithm}
As all the constructive heuristics for solving TSP, the Nearest Neighbor algorithm could be divided into three steps: initialization, selection and insertion. First of all, we write the algorithm as a pseudo-code and then we analyze the three steps in detail.

\begin{verbatim}
NearestNeighbor(G = (V,E))
    // the initial path correspond to the first vertex of the graph
    path <- v_0 in V
    
    // iterate until all the nodes of the graph have been inserted in the path
    while path != V
        // select the vertex not in the path of minimum distance from 
        // the last node inserted in the path
        nextVertex <- MinimumUnseenAdjacent(path, lastVertex)
        // insert the next vertex in the path
        path <- path U nextVertex
    
    // add the starting vertex to close the cycle
    path <- path U v_0
    
    return path
\end{verbatim}
\noindent
The three steps are:
\begin{enumerate}
    \item \textbf{Initialization}: start from the single-node path 0;
    \item \textbf{Selection}: let $(v_0, \dots, v_k)$ be the current path. Find the vertex $v_k+1$ not in the path with minimum distance from $v_k$;
    \item \textbf{Insertion}: insert $v_{k+1}$ immediately after $v_k$.
\end{enumerate}
The second and third steps are repeated until all the vertices are included in the final path. Once this condition is been verified, we need to add the initial vertex to the tail of the path. This is necessary to maintain the Hamiltonian path property.

\subsubsection{Approximation analysis}
The Nearest Neighbor algorithm allows to find a $log(n)$-approximate solution for TSP when the triangular inequality is guaranteed.

\subsubsection{Implementation}
Our implementation is similar to the standard implementation of the Nearest Neighbor algorithm for solving TSP presented in the pseudo-code. The code of the algorithm is divided in two different method implemented in the \verb|Algorithm| class.
The first method, \verb|NearestNeighbor|, takes as input a graph $G$ and, after adding the initial vertex to the path, calls the recursive method \verb|VisitNearestNeighbor| which simply find the closest not visited vertex to the last one present in the path and add it to the path. At the end, when there are no more vertices to visit, \verb|NearestNeighbor| adds again the initial vertex to the path and returns the found Hamiltonian cycle.

\subsubsection{Optimizations implemented}
The main optimization that we made is the use of the \verb|Visited| field. In fact, each vertex has a \verb|Visited| field that is initialized to false and then, when the algorithm is seeking for the closest vertex, if a vertex has already been visited, we skip the weight control on the edge that interconnects that vertex to the current vertex. \\
An other optimization is the use of adjacency lists in the \verb|GetWeight| method, in this way, instead of calculating the weight between one node and another at runtime, a linear scrolling of the adjacency list relating to the node in question is sufficient.

\subsubsection{Complexity analysis}
This algorithm, as the other constructive heuristics, has a computational complexity equal to $\mathcal{O}(V^2)$. In particular, we estimate this complexity starting from some considerations:
\begin{itemize}
    \item For each vertex, we need to find the closest node: this procedure can be executed in linear time, so $\mathcal{O}(|V|)$;
    \item Calculating the distance between two points can be executed in $\mathcal{O}(1)$ because, using the adjacency lists, we can access to the weight between two vertices with constant complexity instruction;
    \item The previous operation must be executed for all the vertices adjacent to the node under analysis. This, in the worst case, can be done in $\mathcal{O}(|V|)$ time.
\end{itemize}
\noindent
So after the considerations above, it is trivial to assume that the final complexity is $\mathcal{O}(|V|^2)$.

\subsection{Closest Insertion}

\subsubsection{Introduction}
The \textit{Closest Insertion} algorithm for solving TSP, as for the Nearest Neighbor algorithm, falls into the class of constructive heuristics.

\subsubsection{Algorithm}
As all the constructive heuristics for solving TSP, the Closest Insertion algorithm could be divided into three steps: initialization, selection and insertion. First of all, we write the algorithm as a pseudo-code and then we analyze the three steps in detail.
\newpage
\begin{verbatim}
ClosestInsertion(G = (V,E))
    // the initial path correspond to the first vertex of the graph
    path <- v_0 in V
    // the remaining vertices that have to be analyzed are all the vertices V 
    // minus the initial vertex v_0
    vertices <- V \ v_0
    // find the vertex with minimum distance from v_0
    j <- MinimumAdjacent(vertices, v_0)
    // remove from the remaining vertices the closest one
    vertices <- vertices \ j
    
    // iterate until all the nodes of the graph have been inserted in the path
    while path != V
        // select the vertex not in the path of minimum distance from one node 
        // present in the path
        nextVertex <- MinimumAdjacent(vertices, path)
        // find an edge (i, j) that minimize the triangular inequality with 
        // respect to v_i, nextVertex and v_j
        path <- AddAfter(v_i, nextVertex)
    
    // add the starting vertex to close the cycle
    path <- path U v_0
    
    return path
\end{verbatim}
\noindent
The three steps are:
\begin{enumerate}
    \item \textbf{Initialization}: start from the single-node path 0. Find the vertex $j$ that minimize $w(0, j)$ and build the partial circuit $C$;
    \item \textbf{Selection}: find a vertex $k$ not in the circuit $C$ that minimize $\delta(k, C)$;
    \item \textbf{Insertion}: find the edge $(i, j)$ of the partial circuit that minimize \textit{w(i, k)} + \textit{w(k, j)} \textminus{ \textit{w(i, j)}} and insert $k$ between $i$ and $j$.
\end{enumerate}
The second and third steps are repeated until all the vertices are included in the final path. Once this condition is been verified, we need to add the initial vertex to the tail of the path. This is necessary to maintain the Hamiltonian path property.

\subsubsection{Approximation analysis}
The Closest Insertion algorithm allows to find a $2$-approximate solution for TSP when the triangular inequality is respected.

\subsubsection{Implementation}
Our implementation is similar to the standard implementation of the Closest Insertion algorithm for solving TSP. The code of the algorithm is written in a single method implemented in the \verb|Algorithm| class.
The method \verb|ClosestInsertion|, takes as input a graph $G$ and, after adding the initial vertex to the path, it simply finds the closest vertex to the initial one and add it to the path. We decided to add the starting vertex again after finding the closest one in the path so that the for each loops in the algorithm were clearer and easier to understand by removing some if conditions from the inside. As long as there are still vertices to add to the path, we seek among all the nodes not yet inserted in the path the closest to the path. We scan the vertices in the path to find through triangular inequality the correct position in which we must add the found closest vertex and then we remove this closest found vertex from the vertices that do not belong to the path. At the end of the procedure, when there are no more vertices to add, the \verb|ClosestInsertion| method returns the found Hamiltonian cycle.

\subsubsection{Optimizations implemented}
We brought some important optimizations in the implementation of the \verb|ClosestInsertion| method. The first one is using a \textit{LinkedList} to store the Hamiltonian cycle. This type of data structure is very useful because it provides the \verb|AddAfter| method, which is an operation that can be performed in constant $\mathcal{O}(1)$ time. This operation is much faster than the simple \verb|InsertAt| operation provided by the \textit{List} data structure which is performed in linear time $\mathcal{O}(n)$.\\ \noindent
The second optimization that we implemented is the fact of using an \textit{HashSet} data structure to hold the vertices not yet inserted in the path and thanks to it, we are able to remove the closest vertex through the \verb|Remove| method in constant time $\mathcal{O}(1)$.\\ \noindent
As for the Nearest Neighbor algorithm, we decide to use an adjacency lists in the \verb|GetWeight| method, in this way, instead of calculating the weight between one node and another at runtime, a linear scrolling of the adjacency list relating to the node in question is sufficient.

\subsubsection{Complexity analysis}
This algorithm has a computational complexity equal to $\mathcal{O}(|V|^3)$. In particular, we estimate this complexity starting from some considerations:
\begin{itemize}
    \item For the initial vertex, we need to find the closest node: this procedure can be executed in linear time, so $\mathcal{O}(|V|)$;
    \item We scan all the vertices not yet in the path to find the closest one by distance among the vertices already in the path. Since calculating the distance between two points can be executed in $\mathcal{O}(1)$ using the adjacency lists. We can access to the weight between two vertices with constant complexity instruction and find the closest vertex, so the total complexity will be $\mathcal{O}(|V|^2)$;
    \item For each couple of nodes in the path we calculate the triangular inequality to find the position in which we have to add the closest vertex: this procedure can be executed in linear time, so $\mathcal{O}(|V|)$;
    \item The previous two operations must be executed for all the vertices not yet inserted in the path that is in linear time $\mathcal{O}(|V|)$. Doing the previous two operations $|V|$ times, it is trivial to assume that the final complexity is $\mathcal{O}(|V|^3)$. 
\end{itemize}

\subsection{2-Approximation}

\subsubsection{Introduction}
The \textit{2-Approximation} algorithm can determine a TSP approximation under the conditions of triangular inequality.

\subsubsection{Definition of MST}
Let $V$ be the set of vertices that makes the weighted graph $G$ and let $E$ be the collection of the edges of that graph. With the aim of analyzing the complexity of algorithms, consider $|V| = n$ and $|E| = m$. \\
A minimum spanning tree $T = (V,E')$ is a tree, where the collection of edges $E'$ is a subset of $E$ of a connected, undirected and weighted graph $G = (V,E)$ which interconnects all the vertices $V$ and with the minimum sum of weights. \\

\noindent
One generic \textit{MST} algorithm is the following: 
\begin{verbatim}
GENERIC-MST(G)
    A = empty set
    while A does not form a spanning tree
        find an edge (u,v) that is safe for A
        A = A U {(u,v)}
    return A
\end{verbatim}
\noindent
Some definition for \textit{MST}:
\begin{enumerate}
    \item A cut $(S, V \setminus S)$ of a graph $G = (V, E)$ is a partition of $V$;
    \item An edge $(u,v) \in E$ crosses a cut $(S, V \setminus S)$ if $u\in S$ and $v \in V \setminus S$ or viceversa;
    \item A cut respects a set $A$ of edges if no edge of $A$ crosses the cut;
    \item Given a cut, the minumim weight edge that crosses the cut is called \textit{light edge}.
\end{enumerate}
\noindent
To determine if an edge is safe, we will use the following theorem: \\

\noindent
\textit{Let $G = (V,E)$ be a weighted, connected and undirected graph. Let $A$ be a subset of $E$ of some \textit{MST} of $G$, let $(S, V \setminus S)$ a cut that respects $A$ and let (u,v) be a light edge for $(S, V \setminus S)$. Then (u,v) is safe for $A$}.

\subsubsection{Algorithm}
We dedicate a section to speak about the MST problem only because the idea behind the 2-Approximation algorithm is to use at first an algorithm to calculate an MST. However, the MST represent a tree and what we want is an Hamiltonian cycle. To do this, we visit the MST in a preorder way and add the root of the MST to the preorder list of vertices. This is an Hamiltonian cycle of the initial graph because it is complete, so there is always an edge between two vertices.\\
We now show the pseudo-code:
\begin{verbatim}
PREORDER(v)
    // print the vertex received as input
    print(v)
    // if the node is a leaf we simply return
    // otherwise we recall the same procedure for each child that vertex v has
    if internal(v) do
        for each u in children(v) do
            PREORDER(u)
    return
\end{verbatim}
\begin{verbatim}
APPROX_METRIC_TSP(G)
    // V is the list of vertices
    V={v_1, ...., v_n}
    // declare the root
    r=v_1
    // MST
    T* <- PRIM(G, r)
    // list of distinct vertex in a preorder way
    H' <- PREORDER(T*, r)
    // we close the list to obtain a cycle adding the initial vertex
    return H = <H', v_1>
\end{verbatim}

\subsubsection{Approximation analysis}
We proceed to analyze the quality of the solution returns by the algorithm:
\begin{enumerate}
    \item The cost of T* is low, actually the lowest;
    \item Let's suppose that two different vertices $u$ and $v$ are not interconnect. The cost of the edge $(u, v)$ is lower than the cost of passing through a third node that connect $u$ and $v$, that is \textit{w(u, v)} $\leq$ \textit{w(u, a)} +{ \textit{w(a, v)}}. So in this case $(u, v)$ is a \textit{shortcut}.
\end{enumerate}

\subsubsection{Analysis of approximation ratio}
We now show the analysis of the approximation ratio of the algorithm:
\begin{enumerate}
    \item \textit{Lower bound to the cost of $H$}: Let $H*$ be the optimal cycle $H* = <v_{j1} \dots v_{jn}, v_{j1}>$. Let $T* = <v_{j1} \dots v_{jn}>$ an Hamiltonian cycle. So, $c(H*) \ge c(T*)$ because in the tree we have remove the last edge to close the cycle so the total weight is surely less than the weight of the Hamiltonian cycle.
    \item \textit{Upper bound to the cost of $H$}: given a tree, a full preorder chain is a list with repetitions of the nodes of the tree which identifies the nodes reached from the recursive calls of \verb|PREORDER|. In a full preorder chain, every edge in $T$ appears exactly twice. So $c(f.p.c.) = 2 \cdot c(T*)$. If we remove the repetitions from the full preorder chain the occurrences of a vertex (leaving the first one in the list) when it occures more than two times, we obtain thanks to the triangular inequality:
    \[
        2 \cdot c(T*) \ge c(H) \Rightarrow 2 \cdot c(H*) \ge 2 \cdot c(T*) \ge c(H)
        \Rightarrow \frac{c(H)}{c(H*)} \le 2
    \]
\end{enumerate}

\subsubsection{Implementation}
The implementation of this algorithm require the use of an algorithm for calculating the MST. We decide to use the Prim's algorithm because it is the one explained by the professor and also because we can simply copy and paste it and use it in the implementation of 2-Approximation algorithm. We proceed with the execution of the Prim's algorithm, starting from the first vertex read in the file, to determine the MST. Then, in the \verb|ApproxMetricTSP| algorithm, we first sort the vertices by their \verb|Key| value and then we utilize the \verb|Parent| field of each vertex to reconstruct a minimum spanning tree, in fact we decide to implement a \verb|Dictionary|, a new data structure that looks more as a tree data structure, in which the \verb|value| parameter is a list of vertices of the vertex indicated in the \verb|key| parameter. Once the MST has been reconstructed, we visit this tree in a preorder way. This operation is performed by the \verb|PreOrder| method which, through recursive calls, visits all the nodes of the tree and adds the visited nodes to a queue in a list. At the end of the preorder visit, the root vertex of the tree is added to the list produced by the \verb|PreOrder| in the queue, in order to build a cycle. This cycle represents the approximation of the TSP.


\subsubsection{Complexity analysis}
We consider the methods implemented:
\begin{enumerate}
    \item \verb|Prim|: Prim's algorithm has a computational complexity equal to $\mathcal{O}(|E| log(|V|))$. In this case, however, the graphs are dense, that means that the graphs are complete, therefore the quantity of edges present in each graph $G$ is equal to $|E| = |V|^2$. Hence, the final complexity of the algorithm is $\mathcal{O}(|V|^2 log(|V|))$;
    \item \textbf{Construction of MST}: the MST has a cardinality of $|V|$ and we check each vertex of the graph $G$ after having sorted them with the \verb|OrderBy| method that has complexity $\mathcal{O}(log |V|)$. The method \verb|Add| of the \verb|Dictionary| used to save the tree has a complexity of $\mathcal{O}(|V|)$ if the number of key/value pairs contained in the dictionary is less than the capacity. We  Therefore, this portion of code has a complexity of $ O(|V|^2 log (|V|))$;
    \item \verb|PreOrder|: we visit all the vertices of the MST in a preorder way. The MST is a tree that connects all the vertices of the original graph $G$. So, the
     complexity will be $\theta(|V|)$.
\end{enumerate}